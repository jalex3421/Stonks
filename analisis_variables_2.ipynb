{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn import neighbors, model_selection, tree\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('all_stocks_5yr.csv', delimiter=',')\n",
    "#se eliminan las filas que tienen valores nulos de cara a realizar posteriores estudios\n",
    "#HABRIA QUE TENERLO IMPUTADO CON VALORES PERDIDOS!!\n",
    "dataset.dropna(axis=0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "atSalida = 'close'\n",
    "atEntrada = ['open','high','low','volume']\n",
    "\n",
    "dataset_output = dataset[atSalida].copy()\n",
    "dataset.drop(atSalida, axis=1, inplace=True)\n",
    "dataset = dataset[atEntrada].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto , las columnas nulas son open, high y  low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Transformación de variables categóricas a numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se va a realizar dicho tipo de transformación , pues para el proyecto se realizará principalmente redes neuronales y regresión polinomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Reducción de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGREGAR DESPUES VARIABLE FECHA!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención del rendimiento con todas las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar la calidad de las técnicas de selección de variables, se va a calcular el rendimiento de una regresión polinomial  si utilizamos todas las variables. Nos hemos decidido por esta técnica, pues es fácil de implementar.\n",
    "\n",
    "Se aplicará el método hold-out para obtener los conjuntos de entrenamiento y de test (70% de datos para entrenar).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE ELIMINARAN LAS FILAS ASOCIADAS A LOS VALORES NULOS PARA PODER REALIZAR LAS COSAS!!! JUNTAR CON LO DE IVAN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rendimiento con regresión polinomial sobre todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, dataset_output, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error en entrenamiento es 0.4663 y en test es 0.4903\n"
     ]
    }
   ],
   "source": [
    "def regresion_polinomial(dataset,dataset_output, p_degree):\n",
    "    # Generamos los conjuntos de entrenamiento y de test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, dataset_output, test_size=0.2, random_state=12)\n",
    "    # Creamos una Pipeline en la que generamos variables polinómicas de grado 2, estandarizamos los datos y aprendemos una regresión lineal\n",
    "    pipePolinomial = Pipeline([('polynomial', PolynomialFeatures(degree=p_degree)),('scaler', StandardScaler()),('regressor', LinearRegression())])\n",
    "    # Entrenamos la Pipeline\n",
    "    pipePolinomial.fit(X_train, y_train)\n",
    "    # Obtenemos el rendimiento en entrenamiento y en test (MSE)\n",
    "    prTrain = pipePolinomial.predict(X_train)\n",
    "    errorTrain = mean_squared_error(y_train, prTrain)\n",
    "    prTest = pipePolinomial.predict(X_test)\n",
    "    errorTest = mean_squared_error(y_test, prTest)\n",
    "    print('El error en entrenamiento es {:.4f} y en test es {:.4f}'.format(errorTrain, errorTest))\n",
    "regresion_polinomial(dataset,dataset_output,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "correlaciones = X_train.corr(method ='pearson')\n",
    "correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la matriz de correlaciones especificando el rango de los valores [-1, 1]\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlaciones, vmin=-1, vmax=1, cmap=plt.cm.rainbow)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(X_train.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "# Añadimos los nombres de las variables en la figura\n",
    "names = X_train.columns\n",
    "ax.set_xticklabels(names, rotation='90')\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras la obtención de matriz de correlaciones, se puede determinar que las variables de entrada están relacionadas entre si de manera muy alta, salvo el volumen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora el rendimiento que se obtendría al eliminar una de éstas variables. Para hacer más completo el experimento, se procederá a crear 3 datasets distintos: cada uno eliminando una variable distinta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Eliminación* *de* *open*, *high*, *low* por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset.copy()\n",
    "dataset_output1 = dataset_output.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['open', 'high', 'low']   \n",
    "for nombrevar in variables:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset1, dataset_output1, test_size=0.2, random_state=12)\n",
    "    X_train = X_train.drop([nombrevar],axis=1)\n",
    "    X_test = X_test.drop([nombrevar],axis=1)\n",
    "\n",
    "    pipePolinomial = Pipeline([('polynomial', PolynomialFeatures(degree=2)),('scaler', StandardScaler()),('regressor', LinearRegression())])\n",
    "    pipePolinomial.fit(X_train, y_train)\n",
    "\n",
    "    #Se obtiene el rendimiento en entrenamiento y en test (MSE)\n",
    "    prTrain = pipePolinomial.predict(X_train)\n",
    "    errorTrain = mean_squared_error(y_train, prTrain)\n",
    "    prTest = pipePolinomial.predict(X_test)\n",
    "    errorTest = mean_squared_error(y_test, prTest)\n",
    "    print(f\"Resutados para la eliminacion de {nombrevar}\")\n",
    "    print('El error en entrenamiento es {:.4f} y en test es {:.4f}'.format(errorTrain, errorTest))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Eliminación* *por* *pares*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pares = [ ['open', 'high'] , ['open', 'low'] , ['high', 'low']]   \n",
    "for par in pares:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset1, dataset_output1, test_size=0.2, random_state=12)\n",
    "    \n",
    "    X_train = X_train.drop([par[0]],axis=1)\n",
    "    X_train = X_train.drop([par[1]],axis=1)\n",
    "\n",
    "    X_test = X_test.drop([par[0]],axis=1)\n",
    "    X_test = X_test.drop([par[1]],axis=1)\n",
    "\n",
    "\n",
    "    pipePolinomial = Pipeline([('polynomial', PolynomialFeatures(degree=2)),('scaler', StandardScaler()),('regressor', LinearRegression())])\n",
    "    pipePolinomial.fit(X_train, y_train)\n",
    "\n",
    "    #Se obtiene el rendimiento en entrenamiento y en test (MSE)\n",
    "    prTrain = pipePolinomial.predict(X_train)\n",
    "    errorTrain = mean_squared_error(y_train, prTrain)\n",
    "    prTest = pipePolinomial.predict(X_test)\n",
    "    errorTest = mean_squared_error(y_test, prTest)\n",
    "    print(f\"Resutados para la eliminacion de {par[0]} y {par[1]}\")\n",
    "    print('El error en entrenamiento es {:.4f} y en test es {:.4f}'.format(errorTrain, errorTest))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Eliminación* *de* *las* *tres* *variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset1, dataset_output1, test_size=0.2, random_state=12)\n",
    "    \n",
    "X_train = X_train.drop(['open'] ,axis=1)\n",
    "X_train = X_train.drop(['low'],axis=1)\n",
    "X_train = X_train.drop(['high'] ,axis=1)\n",
    "\n",
    "X_test = X_test.drop(['open'] ,axis=1)\n",
    "X_test = X_test.drop(['low'],axis=1)\n",
    "X_test = X_test.drop(['high'] ,axis=1)\n",
    "\n",
    "pipePolinomial = Pipeline([('polynomial', PolynomialFeatures(degree=2)),('scaler', StandardScaler()),('regressor', LinearRegression())])\n",
    "pipePolinomial.fit(X_train, y_train)\n",
    "\n",
    "#Se obtiene el rendimiento en entrenamiento y en test (MSE)\n",
    "prTrain = pipePolinomial.predict(X_train)\n",
    "errorTrain = mean_squared_error(y_train, prTrain)\n",
    "prTest = pipePolinomial.predict(X_test)\n",
    "errorTest = mean_squared_error(y_test, prTest)\n",
    "print(\"Resultado para la eliminacion de high, low, y open\")\n",
    "print('El error en entrenamiento es {:.4f} y en test es {:.4f}'.format(errorTrain, errorTest))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras los experimentos realizados, se puede observar que se obtiene un peor resultado al tratar de eliminar cualquiera de las tres variables que cuentan con una mayor correlación -casi perfecta- .\n",
    "\n",
    "Por otro lado, en caso de eliminar una variable,la que menos impacto tiene en el rendimiento del modelo es 'open', y la que más influye es 'high'. \n",
    "\n",
    "En caso de eliminar dos variables,el mayor impacto negativo en el rendimiento vendrá dado por la eliminación de conjunta de 'low' y 'high'. Cosa que es natural, pues representa el valor más bajo y más alto de las acciones de una empresa en un día.\n",
    "\n",
    "La eliminación de 'high', 'low' y 'open' provoca un desenlace nefasto y esperado, pues predecir el valor al final del día de las acciones a partir del volumen de acciones negociadas es sumamente complicado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparativas de métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " La característica principal de las redes recurrentes es que la información puede persistir introduciendo bucles en el diagrama de la red, por lo que, básicamente, pueden «recordar» estados previos y utilizar esta información para decidir cuál será el siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera sencilla, pueden ser pensadas como múltiples copias de la misma red, cada una pasando un mensaje a su sucesor. Por lo que, gracias a su naturaleza, pueden ser relacionadas con listas o secuencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las LSTM pueden aprender dependencias largas, por lo que se podría decir que tienen una «memoria» a más largo plazo. Lo que les hace atractivas para este tipo de problemas, donde la información pasada puede jugar un papel importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIBUJO!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (5.1.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py->keras) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.9)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.22.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.4)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
      "Requirement already satisfied: mock>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (3.0.5)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2faa7ec4c8d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#importing the packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     raise ImportError(\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "#importing the packages \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de datos\n",
    "todataframe = pd.read_csv('all_stocks_5yr.csv', delimiter=',')\n",
    "todataframe.dropna(axis=0, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La comparativa del método se hará con la empresa AAl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = todataframe[todataframe['Name']=='AAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un conjunto de entrenamiento y de test (70% para train, 30% para test)\n",
    "numero_ejemplos_entrenamiento = int(len(df)*0.7)\n",
    "training_set = df.iloc[:numero_ejemplos_entrenamiento, 1:2].values\n",
    "test_set = df.iloc[numero_ejemplos_entrenamiento:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)# Creating a data structure with 60 time-steps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 800):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-d96186e763aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#Adding the first LSTM layer and some Dropout regularisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# Adding a second LSTM layer and some Dropout regularisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# Adding a third LSTM layer and some Dropout regularisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()#Adding the first LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))# Adding a second LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))# Adding a third LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))# Adding the output layer\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "dataset_train = df.iloc[:numero_ejemplos_entrenamiento, 1:2]\n",
    "dataset_test = df.iloc[numero_ejemplos_entrenamiento:, 1:2]dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].valuesinputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 519):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = model.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion del dataframe\n",
    "seriesdata = todataframe.sort_index(ascending=True, axis=0)\n",
    "new_seriesdata = pd.DataFrame(index=range(0,len(todataframe)),columns=['date','close'])\n",
    "length_of_data=len(seriesdata)\n",
    "for i in range(0,length_of_data):\n",
    "    new_seriesdata['date'][i] = seriesdata['date'][i]\n",
    "    new_seriesdata['close'][i] = seriesdata['close'][i]\n",
    "\n",
    "    \n",
    "#Colocar los indices de nuevo\n",
    "new_seriesdata.index = new_seriesdata.date\n",
    "new_seriesdata.drop('date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un conjunto de entrenamiento y de test (70% para train, 30% para test)\n",
    "numero_ejemplos_entrenamiento = int(len(new_seriesdata)*0.7)\n",
    "\n",
    "#Crear conjuntos de train y test con el total de los elementos\n",
    "myseriesdataset = new_seriesdata.values\n",
    "totrain = myseriesdataset[0:numero_ejemplos_entrenamiento,:] #conjunto de ejemplos para entrenar\n",
    "tovalid = myseriesdataset[numero_ejemplos_entrenamiento:,:] #conjunto de ejemplos para validar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "821/821 - 25s - loss: 0.2391 - mean_squared_error: 0.2391\n",
      "Epoch 2/3\n",
      "821/821 - 22s - loss: 0.1745 - mean_squared_error: 0.1745\n",
      "Epoch 3/3\n",
      "821/821 - 23s - loss: 0.1148 - mean_squared_error: 0.1148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cb8f8acc8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertir el dataset en x_train e y_train\n",
    "scalerdata = MinMaxScaler(feature_range=(0, 1))\n",
    "scale_data = scalerdata.fit_transform(myseriesdataset)\n",
    "x_totrain, y_totrain = [], []\n",
    "length_of_totrain=len(totrain)\n",
    "for i in range(60,length_of_totrain):\n",
    "    x_totrain.append(scale_data[i-60:i,0])\n",
    "    y_totrain.append(scale_data[i,0])\n",
    "x_totrain, y_totrain = np.array(x_totrain), np.array(y_totrain)\n",
    "x_totrain = np.reshape(x_totrain, (x_totrain.shape[0],x_totrain.shape[1],1))\n",
    "\n",
    "#LSTM neural network configuracion\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(x_totrain.shape[1],1)))\n",
    "lstm_model.add(LSTM(units=50))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adadelta', metrics= ['mean_squared_error'])\n",
    "lstm_model.fit(x_totrain, y_totrain, epochs=3, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir\n",
    "myinputs = new_seriesdata[len(new_seriesdata) - (len(tovalid)) - 60:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "myinputs  = scalerdata.transform(myinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2491232 ],\n",
       "       [0.24908283],\n",
       "       [0.24899095],\n",
       "       [0.24907307],\n",
       "       [0.24926008],\n",
       "       [0.24975638],\n",
       "       [0.25067288],\n",
       "       [0.25178325],\n",
       "       [0.2529819 ],\n",
       "       [0.2541405 ],\n",
       "       [0.25509575],\n",
       "       [0.255988  ],\n",
       "       [0.25688314],\n",
       "       [0.25776976],\n",
       "       [0.2584892 ],\n",
       "       [0.25905514],\n",
       "       [0.25974008],\n",
       "       [0.26029006],\n",
       "       [0.26070642],\n",
       "       [0.26110286],\n",
       "       [0.26159295],\n",
       "       [0.2626034 ],\n",
       "       [0.26408416],\n",
       "       [0.26557723],\n",
       "       [0.26696166],\n",
       "       [0.26796892],\n",
       "       [0.26843005],\n",
       "       [0.26852897],\n",
       "       [0.2681647 ],\n",
       "       [0.2675032 ],\n",
       "       [0.26661348],\n",
       "       [0.26548728],\n",
       "       [0.2644061 ],\n",
       "       [0.2634856 ],\n",
       "       [0.2625374 ],\n",
       "       [0.26188037],\n",
       "       [0.26140264],\n",
       "       [0.26104096],\n",
       "       [0.26097092],\n",
       "       [0.26138306],\n",
       "       [0.26207218],\n",
       "       [0.26296067],\n",
       "       [0.26401982],\n",
       "       [0.26503006],\n",
       "       [0.2662667 ],\n",
       "       [0.26743725],\n",
       "       [0.26829156],\n",
       "       [0.26939282],\n",
       "       [0.2704896 ],\n",
       "       [0.27150834],\n",
       "       [0.27264214],\n",
       "       [0.27415156],\n",
       "       [0.2758487 ],\n",
       "       [0.27741337],\n",
       "       [0.2788037 ],\n",
       "       [0.27999774],\n",
       "       [0.28092998],\n",
       "       [0.28181195],\n",
       "       [0.2826838 ],\n",
       "       [0.28365818],\n",
       "       [0.28446576],\n",
       "       [0.2850985 ],\n",
       "       [0.28551602],\n",
       "       [0.2858723 ],\n",
       "       [0.2866359 ],\n",
       "       [0.2877113 ],\n",
       "       [0.28911626],\n",
       "       [0.29065487],\n",
       "       [0.29236802],\n",
       "       [0.29425287],\n",
       "       [0.29651758],\n",
       "       [0.29888   ],\n",
       "       [0.30153757],\n",
       "       [0.30441153],\n",
       "       [0.30726752],\n",
       "       [0.30999228],\n",
       "       [0.31259242],\n",
       "       [0.31513837],\n",
       "       [0.31748793],\n",
       "       [0.31970948],\n",
       "       [0.32167155],\n",
       "       [0.32321993],\n",
       "       [0.32452282],\n",
       "       [0.32555   ],\n",
       "       [0.32652965],\n",
       "       [0.32799438],\n",
       "       [0.329621  ],\n",
       "       [0.3316293 ],\n",
       "       [0.33335996],\n",
       "       [0.33483952],\n",
       "       [0.3361389 ],\n",
       "       [0.33736843],\n",
       "       [0.33836296],\n",
       "       [0.33937514],\n",
       "       [0.34054008],\n",
       "       [0.34182745],\n",
       "       [0.34296435],\n",
       "       [0.343889  ],\n",
       "       [0.34467277],\n",
       "       [0.34512806],\n",
       "       [0.3452386 ],\n",
       "       [0.34499562],\n",
       "       [0.3444422 ],\n",
       "       [0.34380797],\n",
       "       [0.3429759 ],\n",
       "       [0.3421081 ],\n",
       "       [0.34147117],\n",
       "       [0.3413533 ],\n",
       "       [0.34163433],\n",
       "       [0.34201998],\n",
       "       [0.34232736],\n",
       "       [0.34234875],\n",
       "       [0.3423742 ],\n",
       "       [0.34234333],\n",
       "       [0.34243754],\n",
       "       [0.3423818 ],\n",
       "       [0.34234136],\n",
       "       [0.34241992],\n",
       "       [0.34296763],\n",
       "       [0.34321964],\n",
       "       [0.34270948],\n",
       "       [0.3415432 ],\n",
       "       [0.33996394],\n",
       "       [0.33818582],\n",
       "       [0.33640498],\n",
       "       [0.334965  ],\n",
       "       [0.33379117],\n",
       "       [0.33279252],\n",
       "       [0.3322308 ],\n",
       "       [0.33202723],\n",
       "       [0.33227503],\n",
       "       [0.3326138 ],\n",
       "       [0.3331913 ],\n",
       "       [0.33378512],\n",
       "       [0.33432868],\n",
       "       [0.33479437],\n",
       "       [0.33507484],\n",
       "       [0.33516482],\n",
       "       [0.33517388],\n",
       "       [0.3351503 ],\n",
       "       [0.33512005],\n",
       "       [0.33526194],\n",
       "       [0.33520195],\n",
       "       [0.33523843],\n",
       "       [0.33501172],\n",
       "       [0.3344726 ],\n",
       "       [0.33376798],\n",
       "       [0.33261976],\n",
       "       [0.33134073],\n",
       "       [0.32968372],\n",
       "       [0.32753482],\n",
       "       [0.32535893],\n",
       "       [0.32329017],\n",
       "       [0.3212661 ],\n",
       "       [0.31933165],\n",
       "       [0.31720865],\n",
       "       [0.31500092],\n",
       "       [0.31309086],\n",
       "       [0.3115414 ],\n",
       "       [0.31027856],\n",
       "       [0.30944982],\n",
       "       [0.30877712],\n",
       "       [0.30834818],\n",
       "       [0.30803746],\n",
       "       [0.30783865],\n",
       "       [0.307331  ],\n",
       "       [0.30671576],\n",
       "       [0.3061748 ],\n",
       "       [0.30573314],\n",
       "       [0.3054987 ],\n",
       "       [0.30581295],\n",
       "       [0.30649608],\n",
       "       [0.30722138],\n",
       "       [0.30814323],\n",
       "       [0.30906788],\n",
       "       [0.31008956],\n",
       "       [0.31134698],\n",
       "       [0.3127021 ],\n",
       "       [0.314372  ],\n",
       "       [0.31624576],\n",
       "       [0.31811967],\n",
       "       [0.31932727],\n",
       "       [0.31967992],\n",
       "       [0.3193354 ],\n",
       "       [0.31901228],\n",
       "       [0.31878278],\n",
       "       [0.31861866],\n",
       "       [0.31864873],\n",
       "       [0.31891742],\n",
       "       [0.3198486 ],\n",
       "       [0.3212562 ],\n",
       "       [0.3227146 ],\n",
       "       [0.32394838],\n",
       "       [0.32517856],\n",
       "       [0.3264456 ],\n",
       "       [0.327208  ],\n",
       "       [0.32750726],\n",
       "       [0.3276488 ],\n",
       "       [0.3279467 ],\n",
       "       [0.32846573],\n",
       "       [0.3291374 ],\n",
       "       [0.33017328],\n",
       "       [0.33159617],\n",
       "       [0.33303097],\n",
       "       [0.33449307],\n",
       "       [0.33607674],\n",
       "       [0.3377978 ],\n",
       "       [0.339597  ],\n",
       "       [0.34137562],\n",
       "       [0.34332594],\n",
       "       [0.3454683 ],\n",
       "       [0.34739244],\n",
       "       [0.3488845 ],\n",
       "       [0.35002407],\n",
       "       [0.3508936 ],\n",
       "       [0.35150227],\n",
       "       [0.351849  ],\n",
       "       [0.35221392],\n",
       "       [0.35223743],\n",
       "       [0.35208857],\n",
       "       [0.3519848 ],\n",
       "       [0.35185456],\n",
       "       [0.35173556],\n",
       "       [0.35157093],\n",
       "       [0.35154685],\n",
       "       [0.3517199 ],\n",
       "       [0.3521738 ],\n",
       "       [0.35281682],\n",
       "       [0.35374317],\n",
       "       [0.35500798],\n",
       "       [0.35666648],\n",
       "       [0.3584438 ],\n",
       "       [0.35996857],\n",
       "       [0.36171976],\n",
       "       [0.36362144],\n",
       "       [0.36561733],\n",
       "       [0.36752674],\n",
       "       [0.36913416],\n",
       "       [0.3703488 ],\n",
       "       [0.37120068],\n",
       "       [0.37169906],\n",
       "       [0.37181467],\n",
       "       [0.37152854],\n",
       "       [0.3710796 ],\n",
       "       [0.37034875],\n",
       "       [0.36955035],\n",
       "       [0.36875674],\n",
       "       [0.36813402],\n",
       "       [0.3675292 ],\n",
       "       [0.36695692],\n",
       "       [0.36648816],\n",
       "       [0.36606047],\n",
       "       [0.3655361 ],\n",
       "       [0.36481825],\n",
       "       [0.3638007 ],\n",
       "       [0.36256945],\n",
       "       [0.36135805],\n",
       "       [0.36015934],\n",
       "       [0.35898057],\n",
       "       [0.3573139 ],\n",
       "       [0.35522527],\n",
       "       [0.35299158],\n",
       "       [0.35069668],\n",
       "       [0.3481085 ],\n",
       "       [0.34515053],\n",
       "       [0.34261063],\n",
       "       [0.34042653],\n",
       "       [0.33843657],\n",
       "       [0.3365719 ],\n",
       "       [0.33494765],\n",
       "       [0.33367983],\n",
       "       [0.3323586 ],\n",
       "       [0.33110505],\n",
       "       [0.3298404 ],\n",
       "       [0.32854414],\n",
       "       [0.32781804],\n",
       "       [0.32763422],\n",
       "       [0.3279618 ],\n",
       "       [0.3284115 ],\n",
       "       [0.32884216],\n",
       "       [0.32907254],\n",
       "       [0.3289278 ],\n",
       "       [0.32878438],\n",
       "       [0.32889017],\n",
       "       [0.32935122],\n",
       "       [0.33018294],\n",
       "       [0.33119494],\n",
       "       [0.332097  ],\n",
       "       [0.3330232 ],\n",
       "       [0.33394843],\n",
       "       [0.33489066],\n",
       "       [0.33646187],\n",
       "       [0.33848986],\n",
       "       [0.3406714 ],\n",
       "       [0.34301797],\n",
       "       [0.3452334 ],\n",
       "       [0.3478001 ],\n",
       "       [0.35051596],\n",
       "       [0.3531556 ],\n",
       "       [0.35564506],\n",
       "       [0.35784876],\n",
       "       [0.3597301 ],\n",
       "       [0.3613267 ],\n",
       "       [0.36257276],\n",
       "       [0.36363316],\n",
       "       [0.364349  ],\n",
       "       [0.36500835],\n",
       "       [0.36544374],\n",
       "       [0.36515585],\n",
       "       [0.36412126],\n",
       "       [0.36257875],\n",
       "       [0.3606894 ],\n",
       "       [0.3588899 ],\n",
       "       [0.3571469 ],\n",
       "       [0.35551175],\n",
       "       [0.35402566],\n",
       "       [0.35244748],\n",
       "       [0.3508189 ],\n",
       "       [0.34908256],\n",
       "       [0.34734166],\n",
       "       [0.34564975],\n",
       "       [0.34406695],\n",
       "       [0.34293863],\n",
       "       [0.342287  ],\n",
       "       [0.34189227],\n",
       "       [0.34172392],\n",
       "       [0.34193045],\n",
       "       [0.3423852 ],\n",
       "       [0.34294376],\n",
       "       [0.34350404],\n",
       "       [0.34422126],\n",
       "       [0.3450376 ],\n",
       "       [0.34616303],\n",
       "       [0.34713086],\n",
       "       [0.34812173],\n",
       "       [0.34901643],\n",
       "       [0.34983125],\n",
       "       [0.35085985],\n",
       "       [0.35205278],\n",
       "       [0.35336122],\n",
       "       [0.35450956],\n",
       "       [0.35539836],\n",
       "       [0.35610965],\n",
       "       [0.3568822 ],\n",
       "       [0.35778818],\n",
       "       [0.35874104],\n",
       "       [0.35978767],\n",
       "       [0.36105847],\n",
       "       [0.3623985 ],\n",
       "       [0.3637718 ],\n",
       "       [0.36501974],\n",
       "       [0.36613455],\n",
       "       [0.36703345],\n",
       "       [0.36795893],\n",
       "       [0.36875978],\n",
       "       [0.369498  ],\n",
       "       [0.37017876],\n",
       "       [0.37068367],\n",
       "       [0.37103182],\n",
       "       [0.37164092],\n",
       "       [0.37301403],\n",
       "       [0.37531805],\n",
       "       [0.3780552 ],\n",
       "       [0.38094223],\n",
       "       [0.38383734],\n",
       "       [0.38656044],\n",
       "       [0.3890564 ],\n",
       "       [0.3913505 ],\n",
       "       [0.39272544],\n",
       "       [0.39297557],\n",
       "       [0.39248312],\n",
       "       [0.39149627],\n",
       "       [0.39022505],\n",
       "       [0.38920537],\n",
       "       [0.38836434],\n",
       "       [0.38726968],\n",
       "       [0.38549557],\n",
       "       [0.38360286]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tostore_test_result = []\n",
    "for i in range(60,myinputs.shape[0]):\n",
    "    tostore_test_result.append(myinputs[i-60:i,0])\n",
    "tostore_test_result = np.array(tostore_test_result)\n",
    "tostore_test_result = np.reshape(tostore_test_result,(tostore_test_result.shape[0],tostore_test_result.shape[1],1))\n",
    "myclosing_priceresult = lstm_model.predict(tostore_test_result)\n",
    "myclosing_priceresult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_resultante = scalerdata.inverse_transform(myclosing_priceresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion_resultante.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tovalid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado del rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MSE obtenido ha sido de : 345.25766857289824\n"
     ]
    }
   ],
   "source": [
    "print(f\"El MSE obtenido ha sido de : {mean_squared_error(tovalid, prediccion_resultante)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "todataframe = pd.read_csv('all_stocks_5yr.csv', delimiter=',')\n",
    "todataframe.dropna(axis=0, inplace = True) \n",
    "todataframe = todataframe[todataframe['Name']=='AAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   open   high    low  close    volume Name\n",
       "0  2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
       "1  2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
       "2  2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
       "3  2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
       "4  2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "atSalida = 'close'\n",
    "atEntrada = ['open','high','low','volume']\n",
    "\n",
    "todataframe_output = todataframe[atSalida].copy()\n",
    "todataframe.drop(atSalida, axis=1, inplace=True)\n",
    "todataframe = todataframe[atEntrada].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecucion apra regresion polinomial de grado 2\n",
      "El error en entrenamiento es 0.1138 y en test es 0.1101\n",
      "------------------------------------------------------\n",
      "Ejecucion apra regresion polinomial de grado 4\n",
      "El error en entrenamiento es 0.0945 y en test es 0.9647\n",
      "------------------------------------------------------\n",
      "Ejecucion apra regresion polinomial de grado 6\n",
      "El error en entrenamiento es 0.0663 y en test es 864.2716\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "grados= [2,4,6]\n",
    "\n",
    "for grado in grados:\n",
    "    print(f\"Ejecucion apra regresion polinomial de grado {grado}\")\n",
    "    regresion_polinomial(todataframe,todataframe_output,grado)\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observaciones*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusiones** **sobre** **comparativa** **de** **métodos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar rendimiento con conjuntos de entrenamiento con regresion polinomial y LSTM "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

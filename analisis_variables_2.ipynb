{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn import neighbors, model_selection, tree\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('all_stocks_5yr.csv', delimiter=',')\n",
    "#se eliminan las filas que tienen valores nulos de cara a realizar posteriores estudios\n",
    "#HABRIA QUE TENERLO IMPUTADO CON VALORES PERDIDOS!!\n",
    "dataset.dropna(axis=0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "atSalida = 'close'\n",
    "atEntrada = ['open','high','low','volume']\n",
    "\n",
    "dataset_output = dataset[atSalida].copy()\n",
    "dataset.drop(atSalida, axis=1, inplace=True)\n",
    "dataset = dataset[atEntrada].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto , las columnas nulas son open, high y  low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Transformación de variables categóricas a numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se va a realizar dicho tipo de transformación , pues para el proyecto se realizará principalmente redes neuronales y regresión polinomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Reducción de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGREGAR DESPUES VARIABLE FECHA!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención del rendimiento con todas las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar la calidad de las técnicas de selección de variables, se va a calcular el rendimiento de una regresión polinomial  si utilizamos todas las variables. Nos hemos decidido por esta técnica, pues es fácil de implementar.\n",
    "\n",
    "Se aplicará el método hold-out para obtener los conjuntos de entrenamiento y de test (70% de datos para entrenar).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE ELIMINARAN LAS FILAS ASOCIADAS A LOS VALORES NULOS PARA PODER REALIZAR LAS COSAS!!! JUNTAR CON LO DE IVAN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rendimiento con regresión polinomial sobre todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, dataset_output, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error en entrenamiento es 0.4663 y en test es 0.4903\n"
     ]
    }
   ],
   "source": [
    "def regresion_polinomial(dataset,dataset_output):\n",
    "    # Generamos los conjuntos de entrenamiento y de test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, dataset_output, test_size=0.2, random_state=12)\n",
    "    # Creamos una Pipeline en la que generamos variables polinómicas de grado 2, estandarizamos los datos y aprendemos una regresión lineal\n",
    "    pipePolinomial = Pipeline([('polynomial', PolynomialFeatures(degree=2)),('scaler', StandardScaler()),('regressor', LinearRegression())])\n",
    "    # Entrenamos la Pipeline\n",
    "    pipePolinomial.fit(X_train, y_train)\n",
    "    # Obtenemos el rendimiento en entrenamiento y en test (MSE)\n",
    "    prTrain = pipePolinomial.predict(X_train)\n",
    "    errorTrain = mean_squared_error(y_train, prTrain)\n",
    "    prTest = pipePolinomial.predict(X_test)\n",
    "    errorTest = mean_squared_error(y_test, prTest)\n",
    "    print('El error en entrenamiento es {:.4f} y en test es {:.4f}'.format(errorTrain, errorTest))\n",
    "regresion_polinomial(dataset,dataset_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "correlaciones = X_train.corr(method ='pearson')\n",
    "correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la matriz de correlaciones especificando el rango de los valores [-1, 1]\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlaciones, vmin=-1, vmax=1, cmap=plt.cm.rainbow)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(X_train.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "# Añadimos los nombres de las variables en la figura\n",
    "names = X_train.columns\n",
    "ax.set_xticklabels(names, rotation='90')\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras la obtención de matriz de correlaciones, se puede determinar que las variables de entrada están relacionadas entre si de manera muy alta, salvo el volumen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora el rendimiento que se obtendría al eliminar una de éstas variables. Para hacer más completo el experimento, se procederá a crear 3 datasets distintos: cada uno eliminando una variable distinta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Eliminación* *de* *open*, *high*, *low* por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset.copy()\n",
    "dataset_output1 = dataset_output.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['open', 'high', 'low']   \n",
    "for nombrevar in variables:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset1, dataset_output1, test_size=0.2, random_state=12)\n",
    "    X_train = X_train.drop([nombrevar],axis=1)\n",
    "    X_test = X_test.drop([nombrevar],axis=1)\n",
    "\n",
    "    pipePolinomial = Pipeline([('polynomial', PolynomialFeatures(degree=2)),('scaler', StandardScaler()),('regressor', LinearRegression())])\n",
    "    pipePolinomial.fit(X_train, y_train)\n",
    "\n",
    "    #Se obtiene el rendimiento en entrenamiento y en test (MSE)\n",
    "    prTrain = pipePolinomial.predict(X_train)\n",
    "    errorTrain = mean_squared_error(y_train, prTrain)\n",
    "    prTest = pipePolinomial.predict(X_test)\n",
    "    errorTest = mean_squared_error(y_test, prTest)\n",
    "    print(f\"Resutados para la eliminacion de {nombrevar}\")\n",
    "    print('El error en entrenamiento es {:.4f} y en test es {:.4f}'.format(errorTrain, errorTest))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Eliminación* *por* *pares*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pares = [ ['open', 'high'] , ['open', 'low'] , ['high', 'low']]   \n",
    "for par in pares:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset1, dataset_output1, test_size=0.2, random_state=12)\n",
    "    \n",
    "    X_train = X_train.drop([par[0]],axis=1)\n",
    "    X_train = X_train.drop([par[1]],axis=1)\n",
    "\n",
    "    X_test = X_test.drop([par[0]],axis=1)\n",
    "    X_test = X_test.drop([par[1]],axis=1)\n",
    "\n",
    "\n",
    "    pipePolinomial = Pipeline([('polynomial', PolynomialFeatures(degree=2)),('scaler', StandardScaler()),('regressor', LinearRegression())])\n",
    "    pipePolinomial.fit(X_train, y_train)\n",
    "\n",
    "    #Se obtiene el rendimiento en entrenamiento y en test (MSE)\n",
    "    prTrain = pipePolinomial.predict(X_train)\n",
    "    errorTrain = mean_squared_error(y_train, prTrain)\n",
    "    prTest = pipePolinomial.predict(X_test)\n",
    "    errorTest = mean_squared_error(y_test, prTest)\n",
    "    print(f\"Resutados para la eliminacion de {par[0]} y {par[1]}\")\n",
    "    print('El error en entrenamiento es {:.4f} y en test es {:.4f}'.format(errorTrain, errorTest))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Eliminación* *de* *las* *tres* *variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset1, dataset_output1, test_size=0.2, random_state=12)\n",
    "    \n",
    "X_train = X_train.drop(['open'] ,axis=1)\n",
    "X_train = X_train.drop(['low'],axis=1)\n",
    "X_train = X_train.drop(['high'] ,axis=1)\n",
    "\n",
    "X_test = X_test.drop(['open'] ,axis=1)\n",
    "X_test = X_test.drop(['low'],axis=1)\n",
    "X_test = X_test.drop(['high'] ,axis=1)\n",
    "\n",
    "pipePolinomial = Pipeline([('polynomial', PolynomialFeatures(degree=2)),('scaler', StandardScaler()),('regressor', LinearRegression())])\n",
    "pipePolinomial.fit(X_train, y_train)\n",
    "\n",
    "#Se obtiene el rendimiento en entrenamiento y en test (MSE)\n",
    "prTrain = pipePolinomial.predict(X_train)\n",
    "errorTrain = mean_squared_error(y_train, prTrain)\n",
    "prTest = pipePolinomial.predict(X_test)\n",
    "errorTest = mean_squared_error(y_test, prTest)\n",
    "print(\"Resultado para la eliminacion de high, low, y open\")\n",
    "print('El error en entrenamiento es {:.4f} y en test es {:.4f}'.format(errorTrain, errorTest))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras los experimentos realizados, se puede observar que se obtiene un peor resultado al tratar de eliminar cualquiera de las tres variables que cuentan con una mayor correlación -casi perfecta- .\n",
    "\n",
    "Por otro lado, en caso de eliminar una variable,la que menos impacto tiene en el rendimiento del modelo es 'open', y la que más influye es 'high'. \n",
    "\n",
    "En caso de eliminar dos variables,el mayor impacto negativo en el rendimiento vendrá dado por la eliminación de conjunta de 'low' y 'high'. Cosa que es natural, pues representa el valor más bajo y más alto de las acciones de una empresa en un día.\n",
    "\n",
    "La eliminación de 'high', 'low' y 'open' provoca un desenlace nefasto y esperado, pues predecir el valor al final del día de las acciones a partir del volumen de acciones negociadas es sumamente complicado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparativas de métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from keras) (1.3.1)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from keras) (3.2.1)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from h5py->keras) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/68/8c/42bbb31a25a708e2e24881724ec7bcea05530492de8b1a2e0d8fe43eb2f6/tensorflow-2.4.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Collecting tensorboard~=2.4 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/44/f5/7feea02a3fb54d5db827ac4b822a7ba8933826b36de21880518250b8733a/tensorboard-2.5.0-py3-none-any.whl\n",
      "Collecting h5py~=2.10.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a1/6b/7f62017e3f0b32438dd90bdc1ff0b7b1448b6cb04a1ed84f37b6de95cd7b/h5py-2.10.0-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (3.15.8)\n",
      "Collecting gast==0.3.3 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/74/7e/622d9849abf3afb81e482ffc170758742e392ee129ce1540611199a59237/tensorflow_estimator-2.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Collecting keras-preprocessing~=1.1.2 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Collecting opt-einsum~=3.3.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl\n",
      "Collecting absl-py~=0.10 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/92/c9/ef0fae29182d7a867d203f0eff8296b60da92098cc41db33a434f4be84bf/absl_py-0.12.0-py3-none-any.whl\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/c1/44179a1cfc5c3b5832a5f9c925161612471ec5f346bcd186235651d74f35/google_auth-1.30.0-py2.py3-none-any.whl\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/74/69/5747a957f95e2e1d252ca41476ae40ce79d70d38151d2e494feb7722860c/tensorboard_data_server-0.6.1-py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/6e/33/1ae0f71395e618d6140fbbc9587cc3156591f748226075e0f7d6f9176522/Markdown-3.3.4-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (41.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/d3/7541e89f1fc456eef157224f597a8bba22589db6369a03eaba68c11f07a0/google_auth_oauthlib-0.4.4-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/c1/499e600ba0c618b451cd9c425ae1c177249940a2086316552fee7d86c954/tensorboard_plugin_wit-1.8.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/bf/28/c4f5796c67ad06bb91d98d543a5e01805c1ff065e08871f78e52d2a331ad/cachetools-4.2.2-py3-none-any.whl\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\" (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/93/0c0f002031f18b53af7a6166103c02b9c0667be528944137cc954ec921b3/rsa-4.7.2-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from markdown>=2.6.8->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/8e/e2/49966924c93909d47612bb47d911448140a2f6c1390aec2f4c1afbe3748f/importlib_metadata-4.0.1-py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/09/c6/d3e3abe5b4f4f16cf0dfc9240ab7ce10c2baa0e268989a4e3ec19e90c84e/urllib3-1.26.4-py2.py3-none-any.whl\n",
      "Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Collecting chardet<5,>=3.0.2 (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/19/c7/fa589626997dd07bd87d9269342ccb74b1720384a4d739a1872bd84fbe68/chardet-4.0.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/8c/715c54e9e34c0c4820f616a913a7de3337d0cd79074dd1bed4dd840f16ae/zipp-3.4.1-py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Installing collected packages: pyasn1, pyasn1-modules, cachetools, rsa, google-auth, tensorboard-data-server, zipp, importlib-metadata, markdown, oauthlib, urllib3, idna, chardet, requests, requests-oauthlib, google-auth-oauthlib, werkzeug, absl-py, tensorboard-plugin-wit, tensorboard, h5py, gast, tensorflow-estimator, keras-preprocessing, opt-einsum, tensorflow\n",
      "  Found existing installation: h5py 3.2.1\n",
      "    Uninstalling h5py-3.2.1:\n",
      "      Successfully uninstalled h5py-3.2.1\n",
      "Successfully installed absl-py-0.12.0 cachetools-4.2.2 chardet-4.0.0 gast-0.3.3 google-auth-1.30.0 google-auth-oauthlib-0.4.4 h5py-2.10.0 idna-2.10 importlib-metadata-4.0.1 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.0 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 urllib3-1.26.4 werkzeug-1.0.1 zipp-3.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the packages \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de datos\n",
    "todataframe = pd.read_csv('all_stocks_5yr.csv', delimiter=',')\n",
    "todataframe.dropna(axis=0, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La comparativa del método se hará con la empresa AAl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "todataframe = todataframe[todataframe['Name']=='AAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion del dataframe\n",
    "seriesdata = todataframe.sort_index(ascending=True, axis=0)\n",
    "new_seriesdata = pd.DataFrame(index=range(0,len(todataframe)),columns=['date','close'])\n",
    "length_of_data=len(seriesdata)\n",
    "for i in range(0,length_of_data):\n",
    "    new_seriesdata['date'][i] = seriesdata['date'][i]\n",
    "    new_seriesdata['close'][i] = seriesdata['close'][i]\n",
    "\n",
    "    \n",
    "#Colocar los indices de nuevo\n",
    "new_seriesdata.index = new_seriesdata.date\n",
    "new_seriesdata.drop('date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un conjunto de entrenamiento y de test (70% para train, 30% para test)\n",
    "numero_ejemplos_entrenamiento = int(len(new_seriesdata)*0.7)\n",
    "\n",
    "#Crear conjuntos de train y test con el total de los elementos\n",
    "myseriesdataset = new_seriesdata.values\n",
    "totrain = myseriesdataset[0:numero_ejemplos_entrenamiento,:] #conjunto de ejemplos para entrenar\n",
    "tovalid = myseriesdataset[numero_ejemplos_entrenamiento:,:] #conjunto de ejemplos para validar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "821/821 - 25s - loss: 0.2391 - mean_squared_error: 0.2391\n",
      "Epoch 2/3\n",
      "821/821 - 22s - loss: 0.1745 - mean_squared_error: 0.1745\n",
      "Epoch 3/3\n",
      "821/821 - 23s - loss: 0.1148 - mean_squared_error: 0.1148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cb8f8acc8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertir el dataset en x_train e y_train\n",
    "scalerdata = MinMaxScaler(feature_range=(0, 1))\n",
    "scale_data = scalerdata.fit_transform(myseriesdataset)\n",
    "x_totrain, y_totrain = [], []\n",
    "length_of_totrain=len(totrain)\n",
    "for i in range(60,length_of_totrain):\n",
    "    x_totrain.append(scale_data[i-60:i,0])\n",
    "    y_totrain.append(scale_data[i,0])\n",
    "x_totrain, y_totrain = np.array(x_totrain), np.array(y_totrain)\n",
    "x_totrain = np.reshape(x_totrain, (x_totrain.shape[0],x_totrain.shape[1],1))\n",
    "\n",
    "#LSTM neural network configuracion\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(x_totrain.shape[1],1)))\n",
    "lstm_model.add(LSTM(units=50))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adadelta', metrics= ['mean_squared_error'])\n",
    "lstm_model.fit(x_totrain, y_totrain, epochs=3, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir\n",
    "myinputs = new_seriesdata[len(new_seriesdata) - (len(tovalid)) - 60:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "myinputs  = scalerdata.transform(myinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2491232 ],\n",
       "       [0.24908283],\n",
       "       [0.24899095],\n",
       "       [0.24907307],\n",
       "       [0.24926008],\n",
       "       [0.24975638],\n",
       "       [0.25067288],\n",
       "       [0.25178325],\n",
       "       [0.2529819 ],\n",
       "       [0.2541405 ],\n",
       "       [0.25509575],\n",
       "       [0.255988  ],\n",
       "       [0.25688314],\n",
       "       [0.25776976],\n",
       "       [0.2584892 ],\n",
       "       [0.25905514],\n",
       "       [0.25974008],\n",
       "       [0.26029006],\n",
       "       [0.26070642],\n",
       "       [0.26110286],\n",
       "       [0.26159295],\n",
       "       [0.2626034 ],\n",
       "       [0.26408416],\n",
       "       [0.26557723],\n",
       "       [0.26696166],\n",
       "       [0.26796892],\n",
       "       [0.26843005],\n",
       "       [0.26852897],\n",
       "       [0.2681647 ],\n",
       "       [0.2675032 ],\n",
       "       [0.26661348],\n",
       "       [0.26548728],\n",
       "       [0.2644061 ],\n",
       "       [0.2634856 ],\n",
       "       [0.2625374 ],\n",
       "       [0.26188037],\n",
       "       [0.26140264],\n",
       "       [0.26104096],\n",
       "       [0.26097092],\n",
       "       [0.26138306],\n",
       "       [0.26207218],\n",
       "       [0.26296067],\n",
       "       [0.26401982],\n",
       "       [0.26503006],\n",
       "       [0.2662667 ],\n",
       "       [0.26743725],\n",
       "       [0.26829156],\n",
       "       [0.26939282],\n",
       "       [0.2704896 ],\n",
       "       [0.27150834],\n",
       "       [0.27264214],\n",
       "       [0.27415156],\n",
       "       [0.2758487 ],\n",
       "       [0.27741337],\n",
       "       [0.2788037 ],\n",
       "       [0.27999774],\n",
       "       [0.28092998],\n",
       "       [0.28181195],\n",
       "       [0.2826838 ],\n",
       "       [0.28365818],\n",
       "       [0.28446576],\n",
       "       [0.2850985 ],\n",
       "       [0.28551602],\n",
       "       [0.2858723 ],\n",
       "       [0.2866359 ],\n",
       "       [0.2877113 ],\n",
       "       [0.28911626],\n",
       "       [0.29065487],\n",
       "       [0.29236802],\n",
       "       [0.29425287],\n",
       "       [0.29651758],\n",
       "       [0.29888   ],\n",
       "       [0.30153757],\n",
       "       [0.30441153],\n",
       "       [0.30726752],\n",
       "       [0.30999228],\n",
       "       [0.31259242],\n",
       "       [0.31513837],\n",
       "       [0.31748793],\n",
       "       [0.31970948],\n",
       "       [0.32167155],\n",
       "       [0.32321993],\n",
       "       [0.32452282],\n",
       "       [0.32555   ],\n",
       "       [0.32652965],\n",
       "       [0.32799438],\n",
       "       [0.329621  ],\n",
       "       [0.3316293 ],\n",
       "       [0.33335996],\n",
       "       [0.33483952],\n",
       "       [0.3361389 ],\n",
       "       [0.33736843],\n",
       "       [0.33836296],\n",
       "       [0.33937514],\n",
       "       [0.34054008],\n",
       "       [0.34182745],\n",
       "       [0.34296435],\n",
       "       [0.343889  ],\n",
       "       [0.34467277],\n",
       "       [0.34512806],\n",
       "       [0.3452386 ],\n",
       "       [0.34499562],\n",
       "       [0.3444422 ],\n",
       "       [0.34380797],\n",
       "       [0.3429759 ],\n",
       "       [0.3421081 ],\n",
       "       [0.34147117],\n",
       "       [0.3413533 ],\n",
       "       [0.34163433],\n",
       "       [0.34201998],\n",
       "       [0.34232736],\n",
       "       [0.34234875],\n",
       "       [0.3423742 ],\n",
       "       [0.34234333],\n",
       "       [0.34243754],\n",
       "       [0.3423818 ],\n",
       "       [0.34234136],\n",
       "       [0.34241992],\n",
       "       [0.34296763],\n",
       "       [0.34321964],\n",
       "       [0.34270948],\n",
       "       [0.3415432 ],\n",
       "       [0.33996394],\n",
       "       [0.33818582],\n",
       "       [0.33640498],\n",
       "       [0.334965  ],\n",
       "       [0.33379117],\n",
       "       [0.33279252],\n",
       "       [0.3322308 ],\n",
       "       [0.33202723],\n",
       "       [0.33227503],\n",
       "       [0.3326138 ],\n",
       "       [0.3331913 ],\n",
       "       [0.33378512],\n",
       "       [0.33432868],\n",
       "       [0.33479437],\n",
       "       [0.33507484],\n",
       "       [0.33516482],\n",
       "       [0.33517388],\n",
       "       [0.3351503 ],\n",
       "       [0.33512005],\n",
       "       [0.33526194],\n",
       "       [0.33520195],\n",
       "       [0.33523843],\n",
       "       [0.33501172],\n",
       "       [0.3344726 ],\n",
       "       [0.33376798],\n",
       "       [0.33261976],\n",
       "       [0.33134073],\n",
       "       [0.32968372],\n",
       "       [0.32753482],\n",
       "       [0.32535893],\n",
       "       [0.32329017],\n",
       "       [0.3212661 ],\n",
       "       [0.31933165],\n",
       "       [0.31720865],\n",
       "       [0.31500092],\n",
       "       [0.31309086],\n",
       "       [0.3115414 ],\n",
       "       [0.31027856],\n",
       "       [0.30944982],\n",
       "       [0.30877712],\n",
       "       [0.30834818],\n",
       "       [0.30803746],\n",
       "       [0.30783865],\n",
       "       [0.307331  ],\n",
       "       [0.30671576],\n",
       "       [0.3061748 ],\n",
       "       [0.30573314],\n",
       "       [0.3054987 ],\n",
       "       [0.30581295],\n",
       "       [0.30649608],\n",
       "       [0.30722138],\n",
       "       [0.30814323],\n",
       "       [0.30906788],\n",
       "       [0.31008956],\n",
       "       [0.31134698],\n",
       "       [0.3127021 ],\n",
       "       [0.314372  ],\n",
       "       [0.31624576],\n",
       "       [0.31811967],\n",
       "       [0.31932727],\n",
       "       [0.31967992],\n",
       "       [0.3193354 ],\n",
       "       [0.31901228],\n",
       "       [0.31878278],\n",
       "       [0.31861866],\n",
       "       [0.31864873],\n",
       "       [0.31891742],\n",
       "       [0.3198486 ],\n",
       "       [0.3212562 ],\n",
       "       [0.3227146 ],\n",
       "       [0.32394838],\n",
       "       [0.32517856],\n",
       "       [0.3264456 ],\n",
       "       [0.327208  ],\n",
       "       [0.32750726],\n",
       "       [0.3276488 ],\n",
       "       [0.3279467 ],\n",
       "       [0.32846573],\n",
       "       [0.3291374 ],\n",
       "       [0.33017328],\n",
       "       [0.33159617],\n",
       "       [0.33303097],\n",
       "       [0.33449307],\n",
       "       [0.33607674],\n",
       "       [0.3377978 ],\n",
       "       [0.339597  ],\n",
       "       [0.34137562],\n",
       "       [0.34332594],\n",
       "       [0.3454683 ],\n",
       "       [0.34739244],\n",
       "       [0.3488845 ],\n",
       "       [0.35002407],\n",
       "       [0.3508936 ],\n",
       "       [0.35150227],\n",
       "       [0.351849  ],\n",
       "       [0.35221392],\n",
       "       [0.35223743],\n",
       "       [0.35208857],\n",
       "       [0.3519848 ],\n",
       "       [0.35185456],\n",
       "       [0.35173556],\n",
       "       [0.35157093],\n",
       "       [0.35154685],\n",
       "       [0.3517199 ],\n",
       "       [0.3521738 ],\n",
       "       [0.35281682],\n",
       "       [0.35374317],\n",
       "       [0.35500798],\n",
       "       [0.35666648],\n",
       "       [0.3584438 ],\n",
       "       [0.35996857],\n",
       "       [0.36171976],\n",
       "       [0.36362144],\n",
       "       [0.36561733],\n",
       "       [0.36752674],\n",
       "       [0.36913416],\n",
       "       [0.3703488 ],\n",
       "       [0.37120068],\n",
       "       [0.37169906],\n",
       "       [0.37181467],\n",
       "       [0.37152854],\n",
       "       [0.3710796 ],\n",
       "       [0.37034875],\n",
       "       [0.36955035],\n",
       "       [0.36875674],\n",
       "       [0.36813402],\n",
       "       [0.3675292 ],\n",
       "       [0.36695692],\n",
       "       [0.36648816],\n",
       "       [0.36606047],\n",
       "       [0.3655361 ],\n",
       "       [0.36481825],\n",
       "       [0.3638007 ],\n",
       "       [0.36256945],\n",
       "       [0.36135805],\n",
       "       [0.36015934],\n",
       "       [0.35898057],\n",
       "       [0.3573139 ],\n",
       "       [0.35522527],\n",
       "       [0.35299158],\n",
       "       [0.35069668],\n",
       "       [0.3481085 ],\n",
       "       [0.34515053],\n",
       "       [0.34261063],\n",
       "       [0.34042653],\n",
       "       [0.33843657],\n",
       "       [0.3365719 ],\n",
       "       [0.33494765],\n",
       "       [0.33367983],\n",
       "       [0.3323586 ],\n",
       "       [0.33110505],\n",
       "       [0.3298404 ],\n",
       "       [0.32854414],\n",
       "       [0.32781804],\n",
       "       [0.32763422],\n",
       "       [0.3279618 ],\n",
       "       [0.3284115 ],\n",
       "       [0.32884216],\n",
       "       [0.32907254],\n",
       "       [0.3289278 ],\n",
       "       [0.32878438],\n",
       "       [0.32889017],\n",
       "       [0.32935122],\n",
       "       [0.33018294],\n",
       "       [0.33119494],\n",
       "       [0.332097  ],\n",
       "       [0.3330232 ],\n",
       "       [0.33394843],\n",
       "       [0.33489066],\n",
       "       [0.33646187],\n",
       "       [0.33848986],\n",
       "       [0.3406714 ],\n",
       "       [0.34301797],\n",
       "       [0.3452334 ],\n",
       "       [0.3478001 ],\n",
       "       [0.35051596],\n",
       "       [0.3531556 ],\n",
       "       [0.35564506],\n",
       "       [0.35784876],\n",
       "       [0.3597301 ],\n",
       "       [0.3613267 ],\n",
       "       [0.36257276],\n",
       "       [0.36363316],\n",
       "       [0.364349  ],\n",
       "       [0.36500835],\n",
       "       [0.36544374],\n",
       "       [0.36515585],\n",
       "       [0.36412126],\n",
       "       [0.36257875],\n",
       "       [0.3606894 ],\n",
       "       [0.3588899 ],\n",
       "       [0.3571469 ],\n",
       "       [0.35551175],\n",
       "       [0.35402566],\n",
       "       [0.35244748],\n",
       "       [0.3508189 ],\n",
       "       [0.34908256],\n",
       "       [0.34734166],\n",
       "       [0.34564975],\n",
       "       [0.34406695],\n",
       "       [0.34293863],\n",
       "       [0.342287  ],\n",
       "       [0.34189227],\n",
       "       [0.34172392],\n",
       "       [0.34193045],\n",
       "       [0.3423852 ],\n",
       "       [0.34294376],\n",
       "       [0.34350404],\n",
       "       [0.34422126],\n",
       "       [0.3450376 ],\n",
       "       [0.34616303],\n",
       "       [0.34713086],\n",
       "       [0.34812173],\n",
       "       [0.34901643],\n",
       "       [0.34983125],\n",
       "       [0.35085985],\n",
       "       [0.35205278],\n",
       "       [0.35336122],\n",
       "       [0.35450956],\n",
       "       [0.35539836],\n",
       "       [0.35610965],\n",
       "       [0.3568822 ],\n",
       "       [0.35778818],\n",
       "       [0.35874104],\n",
       "       [0.35978767],\n",
       "       [0.36105847],\n",
       "       [0.3623985 ],\n",
       "       [0.3637718 ],\n",
       "       [0.36501974],\n",
       "       [0.36613455],\n",
       "       [0.36703345],\n",
       "       [0.36795893],\n",
       "       [0.36875978],\n",
       "       [0.369498  ],\n",
       "       [0.37017876],\n",
       "       [0.37068367],\n",
       "       [0.37103182],\n",
       "       [0.37164092],\n",
       "       [0.37301403],\n",
       "       [0.37531805],\n",
       "       [0.3780552 ],\n",
       "       [0.38094223],\n",
       "       [0.38383734],\n",
       "       [0.38656044],\n",
       "       [0.3890564 ],\n",
       "       [0.3913505 ],\n",
       "       [0.39272544],\n",
       "       [0.39297557],\n",
       "       [0.39248312],\n",
       "       [0.39149627],\n",
       "       [0.39022505],\n",
       "       [0.38920537],\n",
       "       [0.38836434],\n",
       "       [0.38726968],\n",
       "       [0.38549557],\n",
       "       [0.38360286]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tostore_test_result = []\n",
    "for i in range(60,myinputs.shape[0]):\n",
    "    tostore_test_result.append(myinputs[i-60:i,0])\n",
    "tostore_test_result = np.array(tostore_test_result)\n",
    "tostore_test_result = np.reshape(tostore_test_result,(tostore_test_result.shape[0],tostore_test_result.shape[1],1))\n",
    "myclosing_priceresult = lstm_model.predict(tostore_test_result)\n",
    "myclosing_priceresult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_resultante = scalerdata.inverse_transform(myclosing_priceresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion_resultante.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tovalid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado del rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MSE obtenido ha sido de : 345.25766857289824\n"
     ]
    }
   ],
   "source": [
    "print(f\"El MSE obtenido ha sido de : {mean_squared_error(tovalid, prediccion_resultante)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "todataframe = pd.read_csv('all_stocks_5yr.csv', delimiter=',')\n",
    "todataframe.dropna(axis=0, inplace = True) \n",
    "todataframe = todataframe[todataframe['Name']=='AAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1254</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>53.59</td>\n",
       "      <td>53.88</td>\n",
       "      <td>3623078</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1255</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>53.49</td>\n",
       "      <td>53.99</td>\n",
       "      <td>52.03</td>\n",
       "      <td>52.10</td>\n",
       "      <td>5109361</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1256</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>51.99</td>\n",
       "      <td>52.39</td>\n",
       "      <td>49.75</td>\n",
       "      <td>49.76</td>\n",
       "      <td>6878284</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1257</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>49.32</td>\n",
       "      <td>51.50</td>\n",
       "      <td>48.79</td>\n",
       "      <td>51.18</td>\n",
       "      <td>6782480</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1258</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>50.91</td>\n",
       "      <td>51.98</td>\n",
       "      <td>50.89</td>\n",
       "      <td>51.40</td>\n",
       "      <td>4845831</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   open   high    low  close    volume Name\n",
       "0     2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
       "1     2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
       "2     2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
       "3     2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
       "4     2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL\n",
       "...          ...    ...    ...    ...    ...       ...  ...\n",
       "1254  2018-02-01  54.00  54.64  53.59  53.88   3623078  AAL\n",
       "1255  2018-02-02  53.49  53.99  52.03  52.10   5109361  AAL\n",
       "1256  2018-02-05  51.99  52.39  49.75  49.76   6878284  AAL\n",
       "1257  2018-02-06  49.32  51.50  48.79  51.18   6782480  AAL\n",
       "1258  2018-02-07  50.91  51.98  50.89  51.40   4845831  AAL\n",
       "\n",
       "[1259 rows x 7 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "atSalida = 'close'\n",
    "atEntrada = ['open','high','low','volume']\n",
    "\n",
    "todataframe_output = todataframe[atSalida].copy()\n",
    "todataframe.drop(atSalida, axis=1, inplace=True)\n",
    "todataframe = todataframe[atEntrada].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error en entrenamiento es 0.1138 y en test es 0.1101\n"
     ]
    }
   ],
   "source": [
    "regresion_polinomial(todataframe,todataframe_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar rendimiento con conjuntos de entrenamiento con regresion polinomial y LSTM "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37machlearn] *",
   "language": "python",
   "name": "conda-env-py37machlearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduccion de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from category_encoders) (0.12.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from category_encoders) (0.22.2.post1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from category_encoders) (1.16.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from category_encoders) (1.3.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from category_encoders) (0.25.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
      "Requirement already satisfied: six in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\daviz.desktop-829tkaf\\anaconda3\\envs\\py37machlearn\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2019.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from test_helper import Test\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics, neighbors, tree, preprocessing\n",
    "from scipy import stats\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn import neighbors, model_selection, tree\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    "\n",
    "# Se importa la librería de selección de variables\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('all_stocks_5yr.csv', delimiter=',')\n",
    "#se eliminan las filas que tienen valores nulos de cara a realizar posteriores estudios\n",
    "#HABRIA QUE TENERLO IMPUTADO CON VALORES PERDIDOS!!\n",
    "dataset.dropna(axis=0, inplace = True)\n",
    "\n",
    "atSalida = 'close'\n",
    "atEntrada = ['open','high','low','volume']\n",
    "\n",
    "dataset_output = dataset[atSalida].copy()\n",
    "dataset.drop(atSalida, axis=1, inplace=True)\n",
    "dataset = dataset[atEntrada].copy()\n",
    "\n",
    "# SUSTITUIR POR LO BUENO\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, dataset_output, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipePolinomial = Pipeline([('polynomial', PolynomialFeatures(degree=2)),('scaler', StandardScaler()),('regressor', LinearRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correlación mutua: función [*f_regression*](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression)\n",
    "* Información mutua: función [*mutual_info_regression*](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression)\n",
    "\n",
    "\n",
    "Una vez conocida la calidad de cada variable se deben escoger las mejores. Para ello vimos en las clases teóricas que había varias opciones. La librería Scikit-learn ofrece dos de estas técnicas en forma de clases (con sus campos y sus métodos):\n",
    "* Elegir las k mejores con la clase [*SelectKBest*](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest)\n",
    "* Elegir las variables en base al percentil (el % de las variables) con la clase [*SelectPercentile*](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Correlación mutua: función [*f_regression*]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la Pipeline con las fases deseadas de Correlación mutua\n",
    "pipe_f_regression = Pipeline([\n",
    "    ('correlacion_mutua', feature_selection.SelectPercentile(feature_selection.f_regression)),\n",
    "    ('polynomial', PolynomialFeatures(degree=2)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())])\n",
    "# Se crea el grid de híper-parámetros\n",
    "parameters_f_regression = {'correlacion_mutua__percentile': [10, 20, 30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Información mutua: función [*mutual_info_regression*]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la Pipeline con las fases deseadas de Informacion mutua\n",
    "pipe_f_regression = Pipeline([\n",
    "    ('informacion_mutua', feature_selection.SelectPercentile(feature_selection.mutual_info_regression)),\n",
    "    ('polynomial', PolynomialFeatures(degree=2)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())])\n",
    "# Se crea el grid de híper-parámetros\n",
    "parameters_f_regression = {'informacion_mutua__percentile': [10, 20, 30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona la pipe a utilizar\n",
    "pipe = pipe_f_regression\n",
    "parameters = parameters_f_regression\n",
    "\n",
    "# Se llama al constructor de GridSearchCV para que genere todas las combinaciones de los híper-parámetros definidos anteriormente\n",
    "gridSearch_pipe = model_selection.GridSearchCV(pipe,parameters,cv=3,return_train_score=True)\n",
    "# Se realiza el aprendizaje de todos los clasificadores considerados (todas las configuraciones)\n",
    "gridSearch_pipe = gridSearch_pipe.fit(X_train,y_train.values.ravel())\n",
    "# Se muestra la mejor configuración junto con su rendimiento\n",
    "print(gridSearch_pipe.best_score_)\n",
    "print(gridSearch_pipe.best_params_)\n",
    "\n",
    "\n",
    "# Almacenamos el DataFrame con los resultados\n",
    "diccionarioResultados = gridSearch_pipe.cv_results_\n",
    "\n",
    "# Se imprime el mejor porcentaje de acierto y los resultados de todas las configuraciones\n",
    "print(gridSearch_pipe.best_score_,gridSearch_pipe.best_params_)\n",
    "\n",
    "# Se obtiene el rendimiento en entrenamiento y test por la mejor configuración\n",
    "accTrain = gridSearch_pipe.score(X_train,y_train.values.ravel())*100\n",
    "accTest = gridSearch_pipe.score(X_test,y_test.values.ravel())*100\n",
    "print('Resultado en entrenamiento: {}%'.format(accTrain))\n",
    "print('Resultado en test: {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la Pipeline con las fases deseadas para el pipe PCA\n",
    "pipe_pca = Pipeline([('pca', PCA(svd_solver='full')),\n",
    "                 ('polynomial', PolynomialFeatures(degree=2)),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('regressor', LinearRegression())])\n",
    "# Se crea el grid de híper-parámetros\n",
    "parameters_pca = {'pca__n_components': [0.10, 0.30, 0.50, 0.70, 0.90]}\n",
    "# Se llama al constructor de GridSearchCV para que genere todas las combinaciones de los híper-parámetros definidos anteriormente\n",
    "gridSearch_pipe = model_selection.GridSearchCV(pipe_pca,parameters_pca,cv=10,n_jobs=-1,return_train_score=True)\n",
    "# Se realiza el aprendizaje de todos los clasificadores considerados (todas las configuraciones)\n",
    "gridSearch_pipe =  gridSearch_pipe.fit(X_train,y_train)\n",
    "# Se muestra la mejor configuración junto con su rendimiento\n",
    "print(gridSearch_pipe.best_score_)\n",
    "print(gridSearch_pipe.best_params_)\n",
    "\n",
    "\n",
    "# Almacenamos el DataFrame con los resultados\n",
    "diccionarioResultados = gridSearch_pipe.cv_results_\n",
    "\n",
    "# Se imprime el mejor porcentaje de acierto y los resultados de todas las configuraciones\n",
    "print(gridSearch_pipe.best_score_,gridSearch_pipe.best_params_)\n",
    "\n",
    "# Se obtiene el rendimiento en entrenamiento y test por la mejor configuración\n",
    "accTrain = gridSearch_pipe.score(X_train,y_train.values.ravel())*100\n",
    "accTest = gridSearch_pipe.score(X_test,y_test.values.ravel())*100\n",
    "print('Resultado en entrenamiento: {}%'.format(accTrain))\n",
    "print('Resultado en test: {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccióndeinstancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos Wrapers ya que miran la precision con Leave One Out y no tiene en cuanta las clases, las cuales no nos importan ennuestro modelo de regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMHC(regresor, X, y, s=0.1, iteraciones=1000):\n",
    "    \"\"\"\n",
    "     Algoritmo RMHC (Random Mutation Hill Climbing) para la selección de instancias.\n",
    "      Se comienza con una selección aleatoria de s * nEjemplos instancias. Para cada iteración, se elige una instancia\n",
    "      seleccionada y una no seleccionada para ser intercambiadas. Si el intercambio mejora la precisión (leave-one-out) sobre train\n",
    "      se mantiene el cambio, sino se deshace\n",
    "    :param X: Matriz con los ejemplos de entrenamiento (se asume que los ejemplos están normalizados)\n",
    "    :param y: Vector con la salida de los ejemplos en X\n",
    "    :param s: Porcentaje de instancias a ser seleccionadas (s es un valor entre 0 y 1)\n",
    "    :param iteraciones: Número de iteraciones (intercambios) a probar\n",
    "    :return: Vector con la máscara de instancias seleccionadas \n",
    "            (La posición S[i]=True indica que la instancia i ha sido seleccionada y False lo contrario)\n",
    "    \"\"\"\n",
    "    # Como usamos aleatorios en RMHC establecemos la semilla para que el test sea correcto y siempre obtengamos el mismo resultado\n",
    "    np.random.seed(12312)\n",
    "\n",
    "    # En este caso vamos a mantener dos vectores de enteros con los índices de las instancias seleccionadas y no seleccionadas\n",
    "    # Establecemos el número de instancias a seleccionar (es fijo)\n",
    "    nSel = int(X.shape[0]*s)\n",
    "    \n",
    "    # Obtenemos una permutación aleatoria de todos los índices disponibles \n",
    "    # (un array de 0 a X.shape[0] con valores ordenados aleatoriamente): utilizad permutation de Numpy\n",
    "    permute = np.random.permutation(X.shape[0])\n",
    "    \n",
    "    # Cogemos como seleccionadas las instancias correspondientes a los primeros nSel índices  y no seleccionadas el resto#     \n",
    "    seleccionadas = permute[:nSel]\n",
    "    noSeleccionadas = permute[nSel:]\n",
    "\n",
    "    # Calculamos la preicisión con la selección inicial\n",
    "    # Entrenamos regresor con las instancias seleccionadas\n",
    "    regresor.fit(X[seleccionadas], y[seleccionadas])\n",
    "    \n",
    "    # Obtenemos las salidas con leaveOneOut (para no tener en cuenta las instancias seleccionadas como vecinos de sí mismas)\n",
    "    salidas = regresor.predict(X)\n",
    "        \n",
    "    # Calculamos la precisión\n",
    "    acc = metrics.accuracy_score(salidas, y)\n",
    "\n",
    "    # Comenzamos las iteraciones:\n",
    "    #   En cada una, intercambiamos una instancia seleccionada con una que no lo está y comprobamos si mejora la precisión\n",
    "    for i in range(0, iteraciones):\n",
    "        # Seleccionamos un índice de manera aleatoria que nos indica la instancia a eliminar de las seleccionadas: randint de Numpy\n",
    "        quitar = np.random.randint(seleccionadas.size)\n",
    "        \n",
    "        # Seleccionamos un índice de manera aleatoria que nos indica la instancia a añadir a las seleccionadas: randint de Numpy\n",
    "        poner = np.random.randint(noSeleccionadas.size)\n",
    "        \n",
    "        # Guardamos el ejemplo eliminado\n",
    "        aux =  seleccionadas[quitar]\n",
    "        \n",
    "        # Añadimos la nueva instancia seleccionada sustituyendo la que se elimina: intercambio en las listas de seleccionados y no seleccionados\n",
    "        seleccionadas[quitar] = noSeleccionadas[poner]\n",
    "        \n",
    "        # Entrenamos de nuevo regresor\n",
    "        regresor.fit(X[seleccionadas], y[seleccionadas])\n",
    "\n",
    "        # Calculamos la precisión de la solución actual\n",
    "        # Obtenemos las salidas con leaveOneOut (para no tener en cuenta las instancias seleccionadas como vecinos de sí mismas)\n",
    "        salidas = regresor.predict(X)\n",
    "        \n",
    "        # Calculamos la precisión\n",
    "        accNew = metrics.accuracy_score(salidas, y)\n",
    "\n",
    "        # Si la precisión actual es peor que la anterior, devolvemos la instancia eliminada a las seleccionadas\n",
    "        # Sino si la precisión de la solución actual es mejor o igual que la anterior, guardamos la precisión y\n",
    "        #  añadimos la instancia eliminada a las no seleccionadas\n",
    "        if accNew >= acc:\n",
    "            acc = accNew\n",
    "            noSeleccionadas[poner] = aux\n",
    "        else:\n",
    "            seleccionadas[quitar] = aux\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"precision en iteracion {}: {}\".format(i, acc))\n",
    "\n",
    "    # A partir de las seleccionadas creamos la máscara de instancias seleccionadas \n",
    "    # donde True en la posición i indica que la instancia i es seleccionada\n",
    "    S = np.zeros(len(y), bool)\n",
    "    S[seleccionadas] = True\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generacióndevariableseinstancias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
